{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pytz\n",
    "!pip install groq -q\n",
    "!pip install -U langgraph -q\n",
    "!pip install genai google-colab -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph\n",
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import groq\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.tools import tool\n",
    "from google.colab import userdata\n",
    "import google.generativeai as genai\n",
    "import getpass\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "api_key = userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configure the Gemini model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_key_points(user_input):\n",
    "    \"\"\"\n",
    "    Sends the user's study plan input to the Groq Cloud API using the Llama-3.3-70B model\n",
    "    to extract key points.\n",
    "\n",
    "    Parameters:\n",
    "        user_input (str): The study plan provided by the user.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted key points.\n",
    "    \"\"\"\n",
    "    # Define the system prompt and user input for key points extraction\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an helpful assistant that helps students create study plans. Extract key points from study plans provided by users\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Use the Groq client to send a request\n",
    "    groq_client = groq.Client(api_key=\"GROQ_API_KEY\")\n",
    "\n",
    "    try:\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Extract key points from the following study plan:\\n{user_input}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=512,\n",
    "            top_p=1,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        # Extract and process the generated content\n",
    "        generated_content = completion.choices[0].message.content.strip()\n",
    "        key_points = generated_content.split(\"\\n\")\n",
    "\n",
    "        return key_points\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while communicating with Groq Cloud API: {e}\")\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set timezone for Karachi\n",
    "karachi_tz = pytz.timezone('Asia/Karachi')\n",
    "\n",
    "# Get current time in Karachi timezone\n",
    "karachi_time = datetime.now(karachi_tz)\n",
    "current_date = karachi_time.date()\n",
    "# Get current day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_detailed_planning(key_points):\n",
    "    \"\"\"\n",
    "    Generates Mermaid code from the extracted key points.\n",
    "\n",
    "    Parameters:\n",
    "        key_points (list): The extracted key points from the study plan.\n",
    "\n",
    "    Returns:\n",
    "        str: The Mermaid diagram code.\n",
    "    \"\"\"\n",
    "    # Join key points into a structured prompt\n",
    "    key_points_text = \"\\n\".join(key_points)\n",
    "\n",
    "    # Define the system prompt and user input for Mermaid code generation\n",
    "    system_prompt = (\n",
    "          f\"\"\"\n",
    "       Create a detailed weekly study plan based on the provided markdown. The plan should focus on the following:\n",
    "\n",
    "Assignments: List specific tasks (e.g., History Paper, Math Test) with deadlines.\n",
    "Objectives: Clarify the broader goals of the study plan (e.g., mastering the subject, improving time management).\n",
    "Support: Provide 1-2 study techniques, focus strategies, or stress management methods to assist in completing assignments and achieving objectives. Only include these techniques when explicitly requested by the user.\n",
    "Do not break down the tasks day-by-day. Instead, provide a weekly plan that outlines key tasks for the week leading up to deadlines. Ensure the tasks are achievable and aligned with the deadlines and goals. If the user requests, break down further tasks for the next 7 weeks.\n",
    "\n",
    "Use the provided current date in an f-string format like: f\"Today is {current_date} - {karachi_time} - {day}\" - . After providing the weekly plan, ask the user if they need a breakdown for the next 7 weeks.\n",
    "          \"\"\"\n",
    "    )\n",
    "\n",
    "    # Initialize the Groq client\n",
    "    groq_client = groq.Client(api_key=\"GROQ_API_KEY\")\n",
    "\n",
    "    try:\n",
    "        # Send the prompt to the Groq LLM\n",
    "        completion = groq_client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "                    Key Points For Planning:\\n{key_points_text}\n",
    "\n",
    "                    Example Output:\n",
    "Example Output:\n",
    "Weekly Plan for {current_date} - {karachi_time} - {day}:\n",
    "\n",
    "\n",
    "Task 1: Review History Paper instructions and outline key points (due by December 17).\n",
    "Task 2: Begin drafting History Paper (start working on introduction and first section).\n",
    "Task 3: Study for the Math Test (focus on key formulas and problem-solving).\n",
    "Task 4: Complete practice problems for Math Test preparation.\n",
    "Task 5: Start working on the Science Project (gather research materials).\n",
    "Support:\n",
    "Study Techniques:\n",
    "Active recall for studying History and Math.\n",
    "Pomodoro technique (25 minutes of focused work, 5-minute break) to maintain productivity.\n",
    "Summary:\n",
    "This weekly plan ensures the student is focused on high-priority tasks while considering realistic deadlines. It outlines key actions without overwhelming day-to-day granularity, and provides efficient support for accomplishing the tasks.\n",
    "\n",
    "Ask the user:\n",
    "Would you like to continue with a detailed breakdown for the next 7 weeks?\n",
    "                    \"\"\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=1000,\n",
    "            top_p=1,\n",
    "            stream=False\n",
    "        )\n",
    "\n",
    "        # Extract the Mermaid code from the response\n",
    "        generated_mermaid_code = completion.choices[0].message.content.strip()\n",
    "\n",
    "        # Remove explanations and only keep the code\n",
    "        start_idx = generated_mermaid_code.find(\"```\")\n",
    "        end_idx = generated_mermaid_code.rfind(\"```\")\n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            generated_mermaid_code = generated_mermaid_code[start_idx + 3:end_idx].strip()\n",
    "\n",
    "        # Remove any unwanted \"mermaid\" keyword\n",
    "        if generated_mermaid_code.lower().startswith(\"mermaid\"):\n",
    "            generated_mermaid_code = generated_mermaid_code[len(\"mermaid\"):].strip()\n",
    "\n",
    "        return generated_mermaid_code\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while communicating with Groq Cloud API for Mermaid code: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def intelligent_planning(user_input: str) -> str:\n",
    "    \"\"\"Generates intelligent planning based on key points extracted from user input.\"\"\"\n",
    "    keypoints = extract_key_points(user_input)\n",
    "    print(f\"Keypoints Generated: {keypoints}\")\n",
    "    detailed_planning = generate_detailed_planning(keypoints)\n",
    "    return detailed_planning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "api_key = userdata.get('GOOGLE_API_KEY')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "# Method 2: Direct initialization\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=api_key  # Explicitly pass the API key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "tools = [intelligent_planning]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "    \n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[intelligent_planning])\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "user_input = f\"\"\"\n",
    "Struggling to balance my college assignments, soccer practice, and managing my Shopify dropshipping store. \n",
    "I've got a marketing project due next week, need to update product listings, and can't miss tomorrow's soccer training.\n",
    "How can I optimize my time to handle everything without burning out?\n",
    "\"\"\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config,\n",
    "    stream_mode=\"values\")\n",
    "\n",
    "\n",
    "for event in events:\n",
    "    # if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "# snapshot = graph.get_state(config)\n",
    "# existing_message = snapshot.values[\"messages\"][-1]\n",
    "# existing_message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
